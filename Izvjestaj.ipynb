{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6686e87b-9306-4e40-89b6-a40a5ef2ffea",
   "metadata": {},
   "source": [
    "# Analiza, obrada i priprema podataka\n",
    "\n",
    "Datoteka koristena u ovom djelu zadatka je Ciscenje.ipynb.<br><br>\n",
    "\n",
    "Podatke sam ucitala kao pandas dataframe. Uz pomoc linije df.info() sam lako mogla dobiti bitne informacije o kolicini nullova, tipu podataka, broju redaka i slicno.<br><br>\n",
    "\n",
    "Ciscenje sam zapocela sa odbacivanjem supaca koji mi se nisu cinili korisnima. Stupac county je u potpunosti bio ispunjen s nullovima, sto ga cini suvisnim. ID je unikatan sto ne daje bas neku korist, description se sastoji od dugih stringova, razlicitih duljina, sto je beskorisno za model koji ja radim. Stupci sa urlovima isto imaju samo duge stringove koji nece dati nikakvu vrijednost modelu.<br><br>\n",
    "\n",
    "Zamijenila sam beskonacnosti sa nullovima kako kasnije ne bi radile probleme. Odbacila sam sve retke gdje je price 0. Stupac cylinders je tipa string, pa sam izvukla broj cilindara iz stringa i postavila tip int16. Isto tako sam i ostalim brojevima postavila tipove, kako model kasnije, nebi obradivao nepotrebno dugacke tipove. Resetirala sam indekse.<br><br>\n",
    "VIN broj, kako sam nasla na internetu, se sastoji od vise djelova. Zbog toga sam ga razlomila na sastavne djelove da model moze izvuci dodatne korelacije iz toga. Posljednjih par znamenki je unikatni broj vozila, pa ih zbog toga nisam zadrzala.<br><br>\n",
    "\n",
    "U planu mi je bilo napraviti vise tablica, isprobati ih, i pronaci koji set podataka daje najbolji model. Jer kada izbacim sve redove s nullovima, velicina seta podataka se znacajno smanji. Druga opcija mi je bila da smanjim broj redaka, tj. da izbacim sve retke koji imaju veliki broj nullova. Onda, nakon sto pobrisem sve preostale retke sa nullovima, velicina seta se ne smanji toliko drasticno. Treci set je trebao sadrzavati sve stupce. Kod ovog seta sam izbacila sve redove koji imaju broj nullova veci od 3. I onda u konacnici mi je bio plan popuniti prazna mjesta. Krenula sam prvo od toga da uz pomoc vin broja i dodatne tablice koju sam pronasla na internetu, pronadem manufacturera tamo gdje fali. Za ostale stupce mi je bilo u planu izabirati random vrijednosti, koje su povezane s nekim not-null vrijednostima iz istog retka. Npr. izdvajala sam longitude i latitude ovisno o regijama i punila retke kojima su lat i long bili null, a imali su regiju popunjenu. Ovo je bilo dosta vremenski zahtjevno, i s obzirom da su mi blagdani oduzeli dosta vremena, sam odlucila da je bolje da se ne zadrzavam pre vise na ovom djelu. Pa sam si pobrisala te djelove koda da ne dodem u napas da nastavim s time. U konacnici sam koristila samo prvi set podataka, onaj kojemu su pobrisani svi retci sa nullovima."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b26a901-8f03-4865-bef4-e5c35a24b675",
   "metadata": {},
   "source": [
    "# Odabir, treniranje i evaluacija modela\n",
    "\n",
    "Datoteke koristene u ovom djelu zadatka su ML_Model_Vehicles.ipynb i DeepL_Model_Vehicles.ipynb.<br><br>\n",
    "\n",
    "Predvidanje cijene je problem regresije. Kod klasifikacije, cilj algoritma je da iz danih podataka pronade klasu kojoj spada objekt. Npr. klasifikacija slika pasa i macka moze odrediti da li se na slici nalaze macke ili psi, a mozda i oboje. Kod ovakvih algorimatama, algoritam pronalazi rjesenje u skupu ranije postavljenih kategorija, tj. klasa. Za razliku od diskretnog skupa rjesenja u slucaju klasifikacije, regresija nam sluzi da dobijemo kontinuiran skup rjesenja. Kod regresije algoritam trazi brojeve koji najbolje odgovaraju danim podatacima.<br><br>\n",
    "Prije nego sto sam pokrenula modele, morala sam pretvoriti string vreijdnosti u brojcane kako bi ih modeli mogli procesirati. Odvojila sam stupce koji imaju velik i malen broj jedinstvenih vrijednosti. Stupce sa malim brojem jedinstvenih vrijednosti sam uz onehot encoding pretvorila u boolean vektore, znaci onaj stijng koji je prije bio u stupcu je sada jedinica u stupcu koji nosi ime s tom vrijednosti. Stupce sa velikim brojem jednistvanih vreijdnosti nije imalo smisla pretvarati u onehote vektore, u konacnici bih zavrsila sa preko 200 stupaca. Njih sam uz pomoc scikit-learn ordinal encodera pretvorila u stupce intova, od kojih svaki int znaci neka string vrijednost. Kako bih kasnije istu transformaciju mogla koristiti i u apiju, uz pomoc libraryja pickle sam je izvezla van. Isto sam i hardcodeala redosljed stupaca kako se niti ta informacija,koja je bitna za transformaciju, nebi izgubila.<br><br>\n",
    "Za modele sam prvo napravila linearnu regresiju. To je najbrzi algoritam pa samo da vidim je li sve u redu sa podatcima. Brzo sam dobila rezultate, score je bio solidnih 70%, s cime sam si potvrdila da je sve u redu. Sljedeci po redu model je bio RandomForestRegressor, koji je dao dosta dobar score ali je uzeo za to i puno vise vremena. Isprobala sam i opcije sa skaliranim podatcima, ali to nije drasticno poboljsalo rezultate, ako bi ih poboljsalo uopce. Isto tako sam bila slozila i gridsearch, da nade najbolje parametre za random forest algoritam, ali to je trajalo toliko dugo da se nije isplatilo. Isprobala sam i deep learning modele, u pytorchu i tensorflowu. Kako sam imala probleme sa tensorflow paketom, sam pustila te modele da ne izgubim vise vremena. Odlucila sam nastaviti sa onim sto mi pouzdano radi, pa sam RandomForestRegressor model izvukla uz pomoc pickle libraryja."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036dd7ac-89be-4c3b-91e6-9f9406fdaf77",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Izgradnja i kontejnerizacija API-a\n",
    "\n",
    "Dataoteke koristene u ovom dijelu zadatka nalaze se na linku: \n",
    "https://github.com/BabaGata/ml_zadatak<br><br>\n",
    "\n",
    "Za izgradnju APIja sam koristila Flask. Kako bi podataci koji dodu u POST requestu, bili istog oblika kao podatci s kojima je izraden model, bila je potrebna obrada. Podatcima su dodjeljeni pripadajuci tipovi i stringovi su transforemirani uz pomoc istih encodera kao i prije. U konacnici, poziva se predvidanje modela i ispisuje. Napravljen je i Dockerfile. Docker se koristi kao platforma na kojoj mozemo pokrenuti rjesenja neovisno o softwareu, koji uredaj na kojemu pokrecemo rjesenje, koristi. Stvaranjem docker slike, instaliraju se svi potrebni paketi za neometano koristenje aplikacije. Napravljena aplikacija koristi port 8000 pa Vas molim da pri pokretanju docker slike navedete tocan broj porta.<br><br>\n",
    "Kako bi se mogla koristiti aplikacija potrebno je prije pokretanja skinuti i spremiti datoteku random_forest_model.pkl, u istom direktoriju u kojemu se nalazi main.py. Datoteka se moze naci na linku https://drive.google.com/file/d/17ckASaujKpy_bQnYkHaqeyBnogAsgM7p/view?usp=sharing ili generirati pokretanjem notebooka https://github.com/BabaGata/ipynb_datoteke_zadatak/blob/main/ML_Model_Vehicles.ipynb<br><br>\n",
    "Link za exportani docker container : https://drive.google.com/file/d/1iprs2o8kHmUjFJvMAUAxDgU-y9u_oYDW/view?usp=sharing<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966d5b1f-deb0-4d63-b59a-6c1beab2c514",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
